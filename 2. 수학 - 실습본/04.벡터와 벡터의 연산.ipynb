{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db09c77a",
   "metadata": {},
   "source": [
    "# 벡터와 벡터의 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0884d6",
   "metadata": {},
   "source": [
    "## 행렬/벡터의 기본연산\n",
    "- 행렬이나 벡터가 연산하기 위해서는 연산자와 피연산자의 shape 이 동일해야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527774ec",
   "metadata": {},
   "source": [
    "#### 행렬/벡터의 덧셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302edf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([5, 5, 5, 5, 5])\n",
    "\n",
    "x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18125125",
   "metadata": {},
   "source": [
    "#### 행렬/벡터의 곱셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49727bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 3\n",
    "d = np.array([5, 10])\n",
    "\n",
    "d*c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a4d4a",
   "metadata": {},
   "source": [
    "#### 브로드캐스팅\n",
    "- 행렬의 각 항에 동일한 스칼라 값을 모두 연산 \n",
    "- 일벡터의 축약식(생략)의 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa9da27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([10, 11, 12])\n",
    "s = 10 # 10*1벡터 : 의 축약으로 해석된다.\n",
    "a - s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e54fb24",
   "metadata": {},
   "source": [
    "#### 평균제거 벡터 혹은 0평균(zero-mean) 벡터\n",
    "- 벡터내 원소들의 값에 평균값(mean)을 빼준 벡터  \n",
    "$$x - m = \\begin{bmatrix} x_1 - m \\\\ x_2 - m \\\\ \\vdots \\\\x_N - m\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094bfab8",
   "metadata": {},
   "source": [
    "#### 선형조합 (linear combination)\n",
    "- 벡터/행렬에 스칼라를 곱한후 더하거나 뺀것  \n",
    "$$c_1x_1 + c_2x_2 + c_3x_3 + \\dots + c_Lx_L = X$$  \n",
    "$$c_1A_1 + c_2A_2 + c_3A_3 + \\dots + c_LA_L = X$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195ce86",
   "metadata": {},
   "source": [
    "## 벡터와 벡터의 곱셈\n",
    "- 다양한 곱셈의 방식중 **내적(inner product)**에 관해서만 다룬다.  \n",
    "  ㄴ 내적은 두 벡터를 서로 곱한 값으로 $x^Ty$ 형식으로 표기한다.  \n",
    "  ㄴ 점(dot)으로 표기하는 경우도 있어 **닷 프로덕트(dot product)**라고도 한다.  \n",
    "  ㄴ <u>벡터와 벡터의 곱은 스칼라 값</u>이 된다.\n",
    "  \n",
    "     $$x \\cdot y = x^T y = [x_1, x_2, \\dots, x_N]\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\y_N \\end{bmatrix}= \\sum^{N}_{i=1}x_iy_i$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6482624",
   "metadata": {},
   "source": [
    "**벡터와 벡터의 곱이 스칼라가 되는 예**\n",
    "\n",
    "$$x^Ty = [1,\\; 2,\\; 3]\\;\\begin{bmatrix} 4 \\\\ 5 \\\\ 6 \\end{bmatrix} = 1*4+2*5+3*6 = 32$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4092a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[32]]), array([[32]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내적 (2차원 배열임을 주의)\n",
    "x = np.array([[1], [2], [3]])\n",
    "y = np.array([[4], [5], [6]])\n",
    "\n",
    "np.dot(x.T, y), x.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23f0e3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1차원 배열로도 연산이 가능하다.\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "np.dot(x, y), x @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93042f",
   "metadata": {},
   "source": [
    "### 벡터에서 내적이 사용되는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0703a5f",
   "metadata": {},
   "source": [
    "#### 가중합 (weighted sum)\n",
    "- 어떤 행렬/벡터에 특정 가중치를 더하여 합하는 경우를 말한다. 회귀분석시 각각의 독립 변수에 특정 가중치(w)를 더하여 예측력을 높이려는 작업을 예로 들 수 있다.\n",
    "\n",
    "$$ \\sum^N_{i=1}w_ix_i = [w1, w2, \\dots, w_N]\\;\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N \\end{bmatrix} = w^Tx$$\n",
    "\n",
    "\n",
    "덧붙여, 가중치가 없는 일반 합도\n",
    "$1^tx$ 형식으로 표현 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f9ff870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870\n",
      "600.0\n"
     ]
    }
   ],
   "source": [
    "# 가중합의 예시\n",
    "x = np.array([100, 80, 50])\n",
    "w = np.array([3, 4, 5])\n",
    "\n",
    "print(np.dot(x, w))\n",
    "\n",
    "# 일반합의 예시\n",
    "x = np.array([100, 200, 300])\n",
    "w = np.ones(3)\n",
    "\n",
    "print(np.dot(x, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ee397",
   "metadata": {},
   "source": [
    "#### 가중평균 (weighted average)\n",
    "- **각원소를 가중치가 적용된 전체 값에서 차지하는 비율로 표현 한 값**이다.\n",
    "- 각원소의 값을 가중합으로 나눈 값으로. 이를 모두 더하면 1이 된다.\n",
    "- 각 독립변수가 가지는 비중이 다른데 이를 감안하여 평균 값을 산출 하기 위해 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "524f41bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-100.,    0.,  100.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균을 구하는 메소드\n",
    "mean = x.mean()\n",
    "x = x - (np.dot(mean, np.ones(len(x))))\n",
    "x # 평균제거백터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d9b2e",
   "metadata": {},
   "source": [
    "#### 유사도 (similarity)\n",
    "- 이미지 분석등을 위해 두개 이상의 데이터를 1차원 벡터로 변환하였을때, 이 두 벡터가 얼마나 서로 비슷한지를 정의한 정도.\n",
    "- 비교대상의 두 벡터를 서로 내적 하여 나온 값으로 유사도를 측정 한다.\n",
    "- 서로 닮은 정도가 높을 수록 큰 숫자(스칼라)값이 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69e573e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "image_data = load_digits()\n",
    "x = image_data.data\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22b8a498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3064.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 이미지\n",
    "img1 = x[0, :]\n",
    "\n",
    "# 열번째 이미지\n",
    "img10 = x[10, :]\n",
    "\n",
    "# 유사도 (simirality)\n",
    "img1 @ img10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beca626",
   "metadata": {},
   "source": [
    "#### 선형회귀모형\n",
    "\n",
    "**선형회귀모형(linear regression model)**이란 독립 변수 X 에서 종속변수 y를 예측하는 방법으로 독립변수 벡터 x 와 가중치 벡터 w 와의 가중 합을 이용하여 y에 대한 예측값 $\\bar{y}$ 를 계산하는 공식을 말한다.\n",
    "\n",
    "$$\\hat{y} = w_1x_1 + \\dots + w_Nx_N$$\n",
    "\n",
    "predict y 는 정확히 y와 일치하지 않기 떄문에 $hat$ 기호를 붙여 $\\hat{y}$ 로 표기한다.\n",
    "\n",
    "$$\\hat{y} = w^Tx$$\n",
    "\n",
    "\n",
    "**선형회귀모형의 단점**\n",
    "- 독립변수에 기계적입 가중치 대입으로 얻어지는 예측값을 모델화 한 것으로 실제 현실 세계에 적용시 기계적인 반응이 나타나기 어려움으로 예측값의 한계가 존재한다.\n",
    "\n",
    "\n",
    "인공신경망 역시 일종의 선형 회귀 모형이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253de2d",
   "metadata": {},
   "source": [
    "#### 제곱합\n",
    "\n",
    "데이터의 분산(variance)나 표준편차(standard deviation)을 구하는 경우 각각의 원소를 제곱한후 이를 모두 더하거나 더한후 제곱근을 구해야 하는데 이때도 내적을 사용할 수 있다.\n",
    "\n",
    "$$ x^Tx = [x_1, x_2, \\dots, x_N] \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N \\end{bmatrix} = \\sum^N_{i=1}x^2_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadaff37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
